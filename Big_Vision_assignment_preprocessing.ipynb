{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Splitting.py\n"
      ],
      "metadata": {
        "id": "RUMVtUntsz4i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oaqvxHOXss21"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define paths\n",
        "ORIGINAL_DATASET_PATH = \"/Users/aayushjain/Downloads/sportsmot_publish/dataset\"  # Update this with your dataset path\n",
        "NEW_DATASET_PATH = \"/Users/aayushjain/Downloads/sportsmot_publish/basketball_dataset\"  # Where the basketball-only dataset will be stored\n",
        "\n",
        "# Read the basketball sequences from basketball.txt\n",
        "basketball_sequences = set()\n",
        "with open(\"/Users/aayushjain/Downloads/sportsmot_publish/splits_txt/basketball.txt\", \"r\") as f:  # Update the correct path\n",
        "    for line in f:\n",
        "        basketball_sequences.add(line.strip())  # Store sequence names\n",
        "\n",
        "# Process each split (train, val, test)\n",
        "for split in [\"train\", \"val\", \"test\"]:\n",
        "    original_split_path = os.path.join(ORIGINAL_DATASET_PATH, split)\n",
        "    new_split_path = os.path.join(NEW_DATASET_PATH, split)\n",
        "    os.makedirs(new_split_path, exist_ok=True)  # Create new split folder\n",
        "\n",
        "    # Copy only basketball sequences\n",
        "    for seq in os.listdir(original_split_path):\n",
        "        if seq in basketball_sequences:\n",
        "            shutil.copytree(\n",
        "                os.path.join(original_split_path, seq),\n",
        "                os.path.join(new_split_path, seq)\n",
        "            )\n",
        "\n",
        "print(\"Basketball dataset created successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mot_to_yoloTXT.py\n"
      ],
      "metadata": {
        "id": "HJiXvYOetMWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "# Define dataset paths\n",
        "DATASET_PATH = \"/Users/aayushjain/Downloads/sportsmot_publish/basketball_dataset\"\n",
        "SPLITS = [\"train\", \"val\", \"test\"]\n",
        "\n",
        "for split in SPLITS:\n",
        "    data_path = os.path.join(DATASET_PATH, split)\n",
        "    label_path = os.path.join(DATASET_PATH, \"labels\", split)\n",
        "    os.makedirs(label_path, exist_ok=True)\n",
        "\n",
        "    for seq in sorted(os.listdir(data_path)):  # Loop through all folders in train/val/test\n",
        "        seq_path = os.path.join(data_path, seq)\n",
        "        img_path = os.path.join(seq_path, \"img1\")\n",
        "        ann_path = os.path.join(seq_path, \"gt/gt.txt\")\n",
        "\n",
        "        if not os.path.exists(ann_path):\n",
        "            print(f\"Skipping {seq} (No annotation file found)\")\n",
        "            continue  # Skip if no annotations\n",
        "\n",
        "        print(f\"Processing: {seq}\")\n",
        "\n",
        "        with open(ann_path, \"r\") as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            data = line.strip().split(',')\n",
        "            frame_id, obj_id, x, y, w, h, _, class_id, _ = map(float, data)\n",
        "\n",
        "            # Normalize bounding box values\n",
        "            img_file = f\"{int(frame_id):06d}.jpg\"\n",
        "            img_path_full = os.path.join(img_path, img_file)\n",
        "\n",
        "            if not os.path.exists(img_path_full):\n",
        "                continue  # Skip if image does not exist\n",
        "\n",
        "            # Load image dimensions\n",
        "            img = cv2.imread(img_path_full)\n",
        "            img_height, img_width, _ = img.shape\n",
        "\n",
        "            x_center = (x + w / 2) / img_width\n",
        "            y_center = (y + h / 2) / img_height\n",
        "            w /= img_width\n",
        "            h /= img_height\n",
        "\n",
        "            # YOLO format: class_id x_center y_center width height\n",
        "            yolo_format = f\"0 {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\\n\"\n",
        "\n",
        "            # Save the annotation in the corresponding text file\n",
        "            seq_label_path = os.path.join(label_path, seq)\n",
        "            os.makedirs(seq_label_path, exist_ok=True)\n",
        "\n",
        "            txt_filename = f\"{int(frame_id):06d}.txt\"\n",
        "            label_file = os.path.join(seq_label_path, txt_filename)\n",
        "\n",
        "            with open(label_file, \"a\") as out_file:\n",
        "                out_file.write(yolo_format)\n",
        "\n",
        "print(\"✅ All MOT → YOLO conversions complete! Check 'labels/train' and 'labels/val'.\")"
      ],
      "metadata": {
        "id": "ECL-tLa8tUJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening.py\n"
      ],
      "metadata": {
        "id": "KYkMNREbtVrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define dataset path\n",
        "dataset_path = \"/Users/aayushjain/Downloads/sportsmot_publish/basketball_dataset_final\"\n",
        "splits = [\"train\", \"val\", \"test\"]  # Add \"test\" if needed\n",
        "\n",
        "for split in splits:\n",
        "    split_path = os.path.join(dataset_path, split)\n",
        "    new_img_dir = os.path.join(dataset_path, f\"{split}_images\")\n",
        "    new_lbl_dir = os.path.join(dataset_path, f\"{split}_labels\")\n",
        "\n",
        "    os.makedirs(new_img_dir, exist_ok=True)\n",
        "    os.makedirs(new_lbl_dir, exist_ok=True)\n",
        "\n",
        "    for seq_folder in os.listdir(split_path):\n",
        "        if seq_folder.startswith('.'):  # Ignore hidden files like .DS_Store\n",
        "            continue\n",
        "\n",
        "        seq_path = os.path.join(split_path, seq_folder)\n",
        "        img1_path = os.path.join(seq_path, \"img1\")\n",
        "        label_folder = os.path.join(dataset_path, \"labels\", split, seq_folder)\n",
        "\n",
        "        # Move & rename images\n",
        "        if os.path.exists(img1_path):\n",
        "            for img_file in os.listdir(img1_path):\n",
        "                if img_file.startswith('.') or not img_file.endswith('.jpg'):  # Ignore hidden/system files\n",
        "                    continue\n",
        "                frame_id = img_file.split('.')[0]  # Extract frame number (e.g., 0001)\n",
        "                new_name = f\"{seq_folder}_{frame_id}.jpg\"  # Rename with sequence\n",
        "                shutil.move(os.path.join(img1_path, img_file), os.path.join(new_img_dir, new_name))\n",
        "\n",
        "        # Move & rename labels\n",
        "        if os.path.exists(label_folder):\n",
        "            for lbl_file in os.listdir(label_folder):\n",
        "                if lbl_file.startswith('.') or not lbl_file.endswith('.txt'):  # Ignore hidden/system files\n",
        "                    continue\n",
        "                frame_id = lbl_file.split('.')[0]  # Extract frame number\n",
        "                new_name = f\"{seq_folder}_{frame_id}.txt\"  # Rename with sequence\n",
        "                shutil.move(os.path.join(label_folder, lbl_file), os.path.join(new_lbl_dir, new_name))\n",
        "\n",
        "print(\"✅ Renamed and moved all images & labels successfully!\")"
      ],
      "metadata": {
        "id": "TAW1Gfb2tZyr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}